{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data collection",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPn9skt6tBs0U6WJNbEYwSE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_I6wMVanPil",
        "outputId": "dca00faf-c618-4336-b8c8-db700d2c5739"
      },
      "source": [
        "# Non-included packages\n",
        "!pip install biopython"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (1.79)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKy51Ze2nYST"
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "#Tools\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from Bio import SeqIO\n",
        "\n",
        "#Configuration\n",
        "%matplotlib inline"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4hT1mVaWB4L"
      },
      "source": [
        "# Check running in colab\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M6L4_kBnaey",
        "outputId": "3cfd1362-22dd-49e2-8cba-ae098d4f618d"
      },
      "source": [
        "#Configure colab vs local\n",
        "if (IN_COLAB == True) :\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  root_dir = \"/content/drive/My Drive/\"\n",
        "else:\n",
        "  root_dir = \"./\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkWvtmmknai7"
      },
      "source": [
        "# Load hotspots\n",
        "# Only hotspots of up to length 1,500 bp were taken\n",
        "# Those that were shorter than 1,500 bp were padded with N's\n",
        "\n",
        "hotspots = list(SeqIO.parse(root_dir + \"Data/hotspots/fasta/\" + \"combined-max-1500-padded-REMOVED-BAD.fasta\", \"fasta\"))\n",
        "\n",
        "# These random sequences were generated from all parts of the human genome\n",
        "# They were generated with the exact length profile of the hotspots\n",
        "# i.e. hotspots and sequences have the same amount of padding, which is up to 1,500 bps\n",
        "\n",
        "nohotspots = list(SeqIO.parse(root_dir + \"Data/hotspots/fasta/\" + \"sample-max-1500-padded-REMOVED-BAD.fasta\", \"fasta\"))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLpxdDYSngRZ"
      },
      "source": [
        "# Function to convert sequence strings into k-mer words, default size = 6 (hexamer words)\n",
        "def getKmers(sequence, size=5):\n",
        "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]\n",
        "\n",
        "# Which poly's we will be looking for\n",
        "interesting_polys = ['AAAAAAAAAAAA', 'TTTTTTTTTTTT', 'TGTGTGTGTGTG', 'GTGTGTGTGTGT', 'CACACACACACA', 'ACACACACACAC',\n",
        "                     'ATATATATATAT', 'TATATATATATA', 'TTAAAAAAAAAA', 'TTTTTTTTTTAA', 'CTGTAATCCCAG', 'CCTGTAATCCCA',\n",
        "                     'CTGGGATTACAG', 'TGGGATTACAGG', 'TGTAATCCCAGC', 'CCTCAGCCTCCC', 'GCTGGGATTACA', 'GGGAGGCTGAGG',\n",
        "                     'CCTTTTTTTTTT', 'AAAAAAAAAAGG', 'AAAAAAAGAAAG', 'CTTTCTTTTTTT', 'TAAAAATAAAAA', 'TTTTTATTTTTA',\n",
        "                     'CCAAAAAAAAAA', 'GCCTCAGCCTCC', 'TTTTTTTTTTGG', 'CTTTTTTTTTTG', 'CAAAAAAAAAAG', 'GGAGGCTGAGGC' ]\n",
        "\n",
        "# Function to find different poly's in a hotspot and add them as features\n",
        "def compute_polys(string):\n",
        "    matched_polys = np.zeros(len(interesting_polys))\n",
        "    for idx, poly in enumerate(interesting_polys):\n",
        "        #Sum of found polys \n",
        "        \"\"\"\n",
        "        res = len(re.findall(poly, string))\n",
        "        matched_polys[idx] = res\n",
        "        \"\"\"\n",
        "\n",
        "        #Polys at 1 if found\n",
        "        found = string.find(poly)\n",
        "        if (found != -1):\n",
        "            matched_polys[idx] = 1\n",
        "        \n",
        "    return matched_polys\n",
        "\n",
        "def compute_hash(string):\n",
        "    hashv = 0\n",
        "    value = {\"a\":0, \"c\":1, \"g\":2, \"t\":3}\n",
        "    i = len(string)-1\n",
        "    for nucl in string:\n",
        "        if(nucl == 'n'): return -1\n",
        "        hashv = hashv + (4**i) * value[nucl]\n",
        "        i = i - 1\n",
        "    return hashv"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH3fGSYwoI0p"
      },
      "source": [
        "# Definitions on data\n",
        "k = 5 # Kmer size\n",
        "n_seqs = len(hotspots)\n",
        "npolys = len(interesting_polys)\n",
        "nmers = 4**k\n",
        "LEN_ITEM = 1500 # length of a hotspot / no hotspot"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2nfXqgsp_15"
      },
      "source": [
        "hotspots_vector = np.zeros((n_seqs*(4**k + npolys))).reshape(n_seqs, (4**k + npolys))\n",
        "nohotspots_vector = np.zeros((n_seqs*(4**k + npolys))).reshape(n_seqs, (4**k + npolys))\n",
        "\n",
        "for i, seq_record in enumerate(hotspots):\n",
        "    for kmer in getKmers(seq_record.seq, size=k):\n",
        "        hashv = compute_hash(kmer)\n",
        "        if(hashv > -1): hotspots_vector[i, hashv] = hotspots_vector[i, hashv] + 1\n",
        "    hotspots_vector[i, nmers:] = compute_polys(str(seq_record.seq))\n",
        "\n",
        "for i, seq_record in enumerate(nohotspots):\n",
        "    for kmer in getKmers(seq_record.seq, size=k):\n",
        "        hashv = compute_hash(kmer)\n",
        "        if(hashv > -1): nohotspots_vector[i, hashv] = nohotspots_vector[i, hashv] + 1\n",
        "    nohotspots_vector[i, nmers:] = compute_polys(str(seq_record.seq))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmZvVCUDuv8s"
      },
      "source": [
        "labels_hotspots = np.zeros(len(hotspots_vector))\n",
        "labels_nohotspots = np.ones(len(nohotspots_vector))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg5slRq5ukeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37dd8c3c-c141-4735-e2d5-0567b0db0a5d"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "merged_dataset = np.concatenate([hotspots_vector, nohotspots_vector])\n",
        "hotspots = scaler.fit_transform(merged_dataset)\n",
        "labels = np.concatenate([labels_hotspots, labels_nohotspots])\n",
        "\n",
        "print(len(hotspots))\n",
        "print(len(hotspots[0]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77168\n",
            "94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiMKfNc6qDkG"
      },
      "source": [
        "np.save(root_dir + \"Data/hotspots/fasta/hotspots-5k-1polys\",hotspots)\n",
        "np.save(root_dir + \"Data/hotspots/fasta/labels_hotspots-5k-1polys\",labels)"
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}