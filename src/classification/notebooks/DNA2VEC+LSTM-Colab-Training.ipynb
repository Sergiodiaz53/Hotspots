{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNA2VEC+LSTM - New Approach",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVtwaS9H7c2a"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn6EXhwf7fXO"
      },
      "source": [
        "#Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from statistics import mean\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import shuffle\n",
        "from keras import Model, regularizers\n",
        "from keras.layers import Input, Dense, Activation, Dropout, BatchNormalization, Add, Embedding, Bidirectional, LSTM\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIxT4WHG7gYc"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mfKWfl57no5"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPwcsc_R7jmv",
        "outputId": "9964ad0a-46dc-44ec-fcce-d85005d2b0c1"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "root_dir = \"/content/drive/My Drive/\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d8t-SV37tIM"
      },
      "source": [
        "## Load Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79beGvjL7vgW"
      },
      "source": [
        "# Load hotspots kmer list\n",
        "hotspots = np.load(root_dir+\"Data/hotspots/kmers/hotspots-3k-list-500chunk.npy\")\n",
        "\n",
        "\n",
        "# Load labels\n",
        "labels = np.load(root_dir+\"Data/hotspots/kmers/labels_hotspots-3k-list-500chunk.npy\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXZWZpTHIPYn"
      },
      "source": [
        "#[OPTIONAL] limit number of samples to speed up training\n",
        "hotspots, labels = shuffle(hotspots, labels, random_state = 0)\n",
        "hotspots = hotspots[0:round((len(hotspots))/1)]\n",
        "labels = labels[0:round((len(labels))/1)]\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp-YqmIEBIES",
        "outputId": "7f197826-81af-4437-d0ce-1db6538c9371"
      },
      "source": [
        "print('Hotspots loaded, shape:', hotspots.shape)\n",
        "print('Labels loaded, shape: ', labels.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hotspots loaded, shape: (77168, 500)\n",
            "Labels loaded, shape:  (77168,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79p1x9pXBOyF"
      },
      "source": [
        "## Load DNA2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syImFsLZCS0S",
        "outputId": "707d5df9-94c4-49b5-9c52-57a901759036"
      },
      "source": [
        "!git clone https://github.com/Sergiodiaz53/dna2vec.git\n",
        "!pip install -r dna2vec/requirements.txt"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'dna2vec' already exists and is not an empty directory.\n",
            "Requirement already satisfied: arrow==0.8.0 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: biopython==1.79 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 2)) (1.79)\n",
            "Requirement already satisfied: boto==2.46.1 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 3)) (2.46.1)\n",
            "Requirement already satisfied: bz2file==0.98 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 4)) (0.98)\n",
            "Requirement already satisfied: ConfigArgParse==0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: gensim==4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 6)) (4.1.2)\n",
            "Requirement already satisfied: Logbook==1.5.3 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 7)) (1.5.3)\n",
            "Requirement already satisfied: numpy==1.21 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 8)) (1.21.0)\n",
            "Requirement already satisfied: pep8==1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 9)) (1.7.0)\n",
            "Requirement already satisfied: pluggy==0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 10)) (0.4.0)\n",
            "Requirement already satisfied: py==1.4.33 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 11)) (1.4.33)\n",
            "Requirement already satisfied: pytest==3.0.7 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 12)) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil==2.6.0 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 13)) (2.6.0)\n",
            "Requirement already satisfied: requests==2.20 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 14)) (2.20.0)\n",
            "Requirement already satisfied: scipy==1.7.1 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 15)) (1.7.1)\n",
            "Requirement already satisfied: six==1.10.0 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 16)) (1.10.0)\n",
            "Requirement already satisfied: smart-open==5.2.1 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 17)) (5.2.1)\n",
            "Requirement already satisfied: tox==2.7.0 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 18)) (2.7.0)\n",
            "Requirement already satisfied: tox-pyenv==1.0.3 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 19)) (1.0.3)\n",
            "Requirement already satisfied: virtualenv==15.1.0 in /usr/local/lib/python3.7/dist-packages (from -r dna2vec/requirements.txt (line 20)) (15.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest==3.0.7->-r dna2vec/requirements.txt (line 12)) (57.4.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.20->-r dna2vec/requirements.txt (line 14)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.20->-r dna2vec/requirements.txt (line 14)) (2.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.20->-r dna2vec/requirements.txt (line 14)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.20->-r dna2vec/requirements.txt (line 14)) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp4VDxoXCTVM"
      },
      "source": [
        "from dna2vec.dna2vec.multi_k_model import MultiKModel"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rBgfVv4f2zd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3aba04-ea19-4285-a91a-d803643ce57f"
      },
      "source": [
        "K = 3\n",
        "\n",
        "filepath = 'dna2vec/pretrained/dna2vec-20161219-0153-k3to8-100d-10c-29320Mbp-sliding-Xat.w2v'\n",
        "mk_model = MultiKModel(filepath)\n",
        "mk_model = mk_model.model(K)\n",
        "\n",
        "pretrained_weights = mk_model.vectors\n",
        "vocab_size, embedding_dim = pretrained_weights.shape\n",
        "print('Result embedding shape:', pretrained_weights.shape)\n",
        "\n",
        "def word2idx(word):\n",
        "    return mk_model.key_to_index[word]\n",
        "def idx2word(idx):\n",
        "  return mk_model.wv.index_to_key[idx]\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result embedding shape: (64, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcrIO3cYC6mW"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwmAw0K8C8iV"
      },
      "source": [
        "#######################################################################\n",
        "#SeqTokenizer##########################################################\n",
        "#######################################################################\n",
        "\n",
        "hotspots_sequences = []\n",
        "\n",
        "for idx, sample in enumerate(hotspots):\n",
        "    current_seq = []\n",
        "    for idx2, token in enumerate(sample):\n",
        "      token = token.upper()\n",
        "      try:\n",
        "          model_token = word2idx(token)\n",
        "          current_seq.append(model_token)\n",
        "      except:\n",
        "          current_seq.append(\"0\")\n",
        "\n",
        "    hotspots_sequences.append(current_seq)\n",
        "\n",
        "hotspots = hotspots_sequences\n",
        "seq_size = len(hotspots[0])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMZE60XO84IN"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBb7dnFF86Mt"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prhXwiAq87nl"
      },
      "source": [
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.01\n",
        "BATCH_SIZE = 128\n",
        "DROPOUT_RATE = 0.3\n",
        "\n",
        "# LSTM\n",
        "HIDDEN_UNITS_LSTM = 8\n",
        "HIDDEN_UNITS_DENSE_LSTM = 8\n",
        "RECURRENT_DROPOUT_RATE = 0\n",
        "L2_RATE = 1e-05\n",
        "\n",
        "\n",
        "seq_size = len(hotspots[0])\n",
        "hotspots = np.array(hotspots)\n",
        "\n",
        "reduce_lr  = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=25, min_delta=0.01, cooldown=25, min_lr=0.0001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=60, restore_best_weights=True)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXGtXB169A8g"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuX9nE3w9CyV"
      },
      "source": [
        "def createOptimizer(model, learning_rate):\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=optimizer,\n",
        "                metrics = ['accuracy'])\n",
        "  return model\n",
        "\n",
        "def createBidirectionalLSTMModel(seq_lenght, vocab_size, embedding_dim, pretrained_weights_for_embedding):\n",
        "    initializer = keras.initializers.GlorotNormal()\n",
        "\n",
        "    model_input = Input(shape=(seq_lenght))\n",
        "    output = Embedding(input_dim=vocab_size,\n",
        "                        output_dim=embedding_dim,\n",
        "                        input_length=seq_lenght,\n",
        "                        weights=[pretrained_weights_for_embedding])(model_input)\n",
        "    \n",
        "    output  = Bidirectional(LSTM(units=HIDDEN_UNITS_LSTM, kernel_initializer=initializer,\n",
        "                                     kernel_regularizer=regularizers.l2(L2_RATE),\n",
        "                                    dropout=DROPOUT_RATE, recurrent_dropout=RECURRENT_DROPOUT_RATE))(output)    \n",
        "    output = Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "    model = Model(inputs=model_input, outputs=output)\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFH8bqeT9wwF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxk30BMY9y6u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7d6ab8-bb95-4a00-c081-4aa27d633e48"
      },
      "source": [
        "test_acc_max = 0\n",
        "best_model = \"\"\n",
        "x_test_max = \"\"\n",
        "y_true_max = \"\"\n",
        "best_history = \"\"\n",
        "scores = []\n",
        "\n",
        "for i in range(0,1):\n",
        "\n",
        "  hs_train, hs_test, y_train, y_test = train_test_split(hotspots, labels, test_size=0.2, shuffle=True)\n",
        "\n",
        "  hs_train = hs_train.astype('float32')\n",
        "  hs_test = hs_test.astype('float32')\n",
        "\n",
        "  model = createBidirectionalLSTMModel(seq_size, vocab_size, embedding_dim, pretrained_weights)\n",
        "  model = createOptimizer(model, LEARNING_RATE)\n",
        "  history = model.fit(hs_train, y_train, validation_data=(hs_test, y_test), epochs=EPOCHS, batch_size=BATCH_SIZE, shuffle=True, verbose=2, callbacks=[reduce_lr, early_stopping])\n",
        "  test_loss, test_acc = model.evaluate(hs_test, y_test)\n",
        "  scores.append(test_acc)\n",
        "  if(test_acc > test_acc_max):\n",
        "    test_acc_max = test_acc\n",
        "    best_model = model\n",
        "    x_test_max = hs_test\n",
        "    y_true_max = y_test\n",
        "    best_history = history\n",
        "\n",
        "print('Max accuracy:', test_acc_max)\n",
        "print('Mean accuracy:', mean(scores))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "483/483 - 105s - loss: 0.6859 - accuracy: 0.5563 - val_loss: 0.6763 - val_accuracy: 0.5816\n",
            "Epoch 2/50\n",
            "483/483 - 101s - loss: 0.6760 - accuracy: 0.5782 - val_loss: 0.6739 - val_accuracy: 0.5790\n",
            "Epoch 3/50\n",
            "483/483 - 102s - loss: 0.6807 - accuracy: 0.5674 - val_loss: 0.6802 - val_accuracy: 0.5714\n",
            "Epoch 4/50\n",
            "483/483 - 102s - loss: 0.6711 - accuracy: 0.5822 - val_loss: 0.6719 - val_accuracy: 0.5897\n",
            "Epoch 5/50\n",
            "483/483 - 102s - loss: 0.6683 - accuracy: 0.5956 - val_loss: 0.6688 - val_accuracy: 0.5969\n",
            "Epoch 6/50\n",
            "483/483 - 102s - loss: 0.6670 - accuracy: 0.5982 - val_loss: 0.6684 - val_accuracy: 0.5946\n",
            "Epoch 7/50\n",
            "483/483 - 102s - loss: 0.6652 - accuracy: 0.6002 - val_loss: 0.6689 - val_accuracy: 0.5899\n",
            "Epoch 8/50\n",
            "483/483 - 102s - loss: 0.6647 - accuracy: 0.6019 - val_loss: 0.6784 - val_accuracy: 0.5684\n",
            "Epoch 9/50\n",
            "483/483 - 102s - loss: 0.6711 - accuracy: 0.5805 - val_loss: 0.6688 - val_accuracy: 0.5954\n",
            "Epoch 10/50\n",
            "483/483 - 102s - loss: 0.6673 - accuracy: 0.5999 - val_loss: 0.6663 - val_accuracy: 0.6009\n",
            "Epoch 11/50\n",
            "483/483 - 102s - loss: 0.6661 - accuracy: 0.6027 - val_loss: 0.6643 - val_accuracy: 0.6047\n",
            "Epoch 12/50\n",
            "483/483 - 102s - loss: 0.6658 - accuracy: 0.5985 - val_loss: 0.6686 - val_accuracy: 0.5995\n",
            "Epoch 13/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjTYowUs-K8N"
      },
      "source": [
        "# Results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6-5QfCcUomO"
      },
      "source": [
        "## Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NWBOgUPUqGG"
      },
      "source": [
        "y_pred=best_model.predict(x_test_max).ravel()\n",
        "print(classification_report(y_true_max, (y_pred > 0.5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXufDplJ-U7B"
      },
      "source": [
        "## ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9ZzOn8FS6Wr"
      },
      "source": [
        "# calling the roc_curve, extract the probability of \n",
        "# the positive class from the predicted probability\n",
        "fpr, tpr, thresholds = roc_curve(y_true_max, y_pred)\n",
        "\n",
        "# AUC score that summarizes the ROC curve\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.plot(fpr, tpr, lw = 2, label = 'ROC AUC: {:.2f}'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1],\n",
        "         linestyle = '--',\n",
        "         color = (0.6, 0.6, 0.6),\n",
        "         label = 'random guessing')\n",
        "plt.plot([0, 0, 1], [0, 1, 1],\n",
        "         linestyle = ':',\n",
        "         color = 'black', \n",
        "         label = 'perfect performance')\n",
        "\n",
        "plt.xlim([-0.05, 1.05])\n",
        "plt.ylim([-0.05, 1.05])\n",
        "plt.xlabel('false positive rate')\n",
        "plt.ylabel('true positive rate')\n",
        "plt.title('Receiver Operator Characteristic')\n",
        "plt.legend(loc = \"lower right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikBVvNi6UYCS"
      },
      "source": [
        "## Precission Recall Curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciMC30yZUbR8"
      },
      "source": [
        "precision, recall, thresholds = precision_recall_curve(y_true_max, y_pred)\n",
        "\n",
        "# AUC score that summarizes the precision recall curve\n",
        "avg_precision = average_precision_score(y_true_max, y_pred)\n",
        "\n",
        "label = 'Precision Recall AUC: {:.2f}'.format(avg_precision)\n",
        "plt.plot(recall, precision, lw = 2, label = label)\n",
        "plt.xlabel('Recall')  \n",
        "plt.ylabel('Precision')  \n",
        "plt.title('Precision Recall Curve')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hywksfyEUUej"
      },
      "source": [
        "## Confussion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gmz0QvH-j0w"
      },
      "source": [
        "y_pred=best_model.predict(x_test_max).ravel()\n",
        "y_pred = y_pred > 0.5\n",
        "\n",
        "class_names = [\"Hotspot\", \"No Hotspot\"]\n",
        "con_mat = tf.math.confusion_matrix(labels=y_true_max, predictions=y_pred).numpy()\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "con_mat_df = pd.DataFrame(con_mat_norm, index = class_names, columns = class_names)\n",
        "\n",
        "print('Accuracy Y_test: ', accuracy_score(y_true_max, y_pred))\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnWcKWCO-PSh"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEKzOiQZ-Mb5"
      },
      "source": [
        "plt.plot(best_history.history['accuracy'])\n",
        "plt.plot(best_history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3dFS1QA-R-n"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-npZrUg-TSx"
      },
      "source": [
        "plt.plot(best_history.history['loss'])\n",
        "plt.plot(best_history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zViqnS9C6PKA"
      },
      "source": [
        "# Save Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xHIkEGS6SCL"
      },
      "source": [
        "model.save(root_dir+'ResNetmodel-2kEpochs.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}